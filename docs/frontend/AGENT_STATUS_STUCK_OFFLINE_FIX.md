# Agent Status Stuck Offline Fix

## Date
January 2025

## Status
‚úÖ **IMPLEMENTED**

---

## Problem Summary

After fixing the agent status flickering issue, a new related problem emerged:

**Symptom**: Agents that are actually connected and online would eventually show as "Offline" in the frontend and **never recover**, even though they're still connected and sending PONG heartbeats.

**Impact**: Users had to restart agents to get the frontend to show them as online again.

---

## Root Cause

### The Issue Flow

1. **Agent is connected** and sends PONG responses every 30s
2. **Backend PONG handler** updates `last_ping` in database
3. **‚ùå NO BROADCAST** happens (because only `last_ping` is updated, not `status`)
4. **AgentHeartbeatMonitor** (runs every 30s) checks `last_ping` timestamps
5. If `last_ping` > 90s old, marks agent as OFFLINE
6. **‚úÖ BROADCASTS OFFLINE** (because status changed from 'online' ‚Üí 'offline')
7. **Frontend receives OFFLINE** status and displays agent as offline
8. **Agent continues sending PONGs** ‚Üí Updates `last_ping` ‚Üí **‚ùå NO BROADCAST**
9. **Agent stuck OFFLINE forever** because status never changes back to 'online'

### The Core Problem

The `updateAgent()` method only broadcasts status changes when the `status` field is explicitly updated:

```typescript
// backend/src/services/agent.service.ts:258-261
if (oldAgent && updates.status && oldAgent.status !== updates.status) {
  await this.broadcastAgentStatusChange(updatedAgent as any, 'status_changed');
  this.emit('agent:status-changed', updatedAgent, oldAgent.status);
}
```

When the PONG handler updates only `last_ping`:

```typescript
// Before fix - agent-handler.ts:816-818
await this.services.agentService.updateAgent(connection.agentId, {
  last_ping: new Date()  // ‚Üê Only updates timestamp, no status field
});
```

**No broadcast occurs** because `updates.status` is undefined.

### Race Condition Timeline

```
T+0s    Agent connected, status='online'
T+30s   Agent sends PONG ‚Üí Updates last_ping ‚Üí No broadcast
T+60s   Agent sends PONG ‚Üí Updates last_ping ‚Üí No broadcast
T+90s   Agent sends PONG ‚Üí Updates last_ping ‚Üí No broadcast
T+95s   AgentHeartbeatMonitor runs ‚Üí Sees last_ping is 5s old ‚Üí ‚úÖ Agent is healthy
T+120s  Agent sends PONG ‚Üí Updates last_ping ‚Üí No broadcast
T+125s  AgentHeartbeatMonitor runs ‚Üí Sees last_ping is 5s old ‚Üí ‚úÖ Agent is healthy

--- NETWORK HICCUP OR PROCESSING DELAY ---

T+150s  Agent sends PONG (delayed by 30s due to network/processing)
T+155s  AgentHeartbeatMonitor runs
        ‚Üí Sees last_ping is 35s old (from T+120s)
        ‚Üí Still < 90s threshold ‚Üí ‚úÖ Agent is healthy

T+180s  PONG still hasn't arrived/been processed
T+185s  AgentHeartbeatMonitor runs
        ‚Üí Sees last_ping is 65s old
        ‚Üí Still < 90s threshold ‚Üí ‚úÖ Agent is healthy

T+210s  PONG still delayed
T+215s  AgentHeartbeatMonitor runs
        ‚Üí Sees last_ping is 95s old (> 90s timeout!)
        ‚Üí ‚ùå Marks agent OFFLINE
        ‚Üí ‚úÖ BROADCASTS status='offline'

T+220s  Delayed PONG finally processed
        ‚Üí Updates last_ping to T+220s
        ‚Üí ‚ùå NO BROADCAST (status field not updated)
        ‚Üí Agent status in DB: 'offline', last_ping = T+220s
        ‚Üí Frontend shows: OFFLINE

T+250s  Agent sends new PONG
        ‚Üí Updates last_ping to T+250s
        ‚Üí ‚ùå NO BROADCAST
        ‚Üí Frontend still shows: OFFLINE

T+280s  Agent sends PONG...
        ‚Üí Updates last_ping...
        ‚Üí ‚ùå NO BROADCAST
        ‚Üí Frontend still shows: OFFLINE

üîÑ AGENT STUCK OFFLINE FOREVER
```

---

## The Fix

### Modified File
`backend/src/websocket/agent-handler.ts` - Lines 812-855

### Implementation

Added status recovery logic to the PONG handler:

```typescript
private async handlePong(connection: AgentConnection, message: WebSocketMessage): Promise<void> {
  try {
    if (connection.agentId) {
      // Get current agent to check status
      const agent = await this.services.agentService.getAgent(connection.agentId);

      // If agent is marked offline but is still connected and responding to PINGs,
      // update status back to online (this will trigger a broadcast)
      if (agent && agent.status === 'offline') {
        this.server.log.info({
          connectionId: connection.connectionId,
          agentId: connection.agentId
        }, '[PING/PONG] Agent was offline but is responding to PINGs - recovering to online');

        await this.services.agentService.updateAgent(connection.agentId, {
          status: 'online',  // This triggers broadcast
          last_ping: new Date()
        });
      } else {
        // Agent is already online, just update heartbeat timestamp (no broadcast)
        await this.services.agentService.updateAgent(connection.agentId, {
          last_ping: new Date()
        });

        this.server.log.debug({
          connectionId: connection.connectionId,
          agentId: connection.agentId
        }, '[PING/PONG] Updated agent last_ping from PONG response');
      }
    }
  } catch (error) {
    this.server.log.error({
      error,
      connectionId: connection.connectionId,
      agentId: connection.agentId
    }, 'Failed to update last_ping for agent');
  }

  // Notify HeartbeatManager that pong was received
  if (message.payload.timestamp) {
    this.dependencies.heartbeatManager.recordPong(connection.connectionId, message.payload.timestamp);
  }
}
```

### How It Works

1. **On every PONG**, fetch the current agent from database
2. **Check if status is 'offline'**:
   - **YES**: Agent was incorrectly marked offline ‚Üí Update status to 'online' + last_ping
     - This triggers `broadcastAgentStatusChange()` because status is changing
     - Frontend receives AGENT_STATUS message with status='online'
     - Agent recovers to online state ‚úÖ
   - **NO**: Agent is already online ‚Üí Just update last_ping (no broadcast needed)
     - Avoids flooding frontend with unnecessary status messages
     - Still keeps agent alive in database

### Why This Works

- **Self-healing**: Agents automatically recover from incorrectly marked offline status
- **Minimal overhead**: Only fetches agent and broadcasts when needed (status mismatch)
- **No message flood**: Normal PONGs don't trigger broadcasts, only recovery PONGs do
- **Handles race conditions**: Even if AgentHeartbeatMonitor marks agent offline during a network hiccup, the next PONG will recover it

---

## Testing

### Before Fix
1. Start agent ‚Üí Shows Online ‚úÖ
2. Wait for network delay or processing delay
3. AgentHeartbeatMonitor marks it Offline ‚Üí Shows Offline ‚úÖ
4. Agent continues sending PONGs ‚Üí **Stays Offline forever** ‚ùå
5. Must restart agent to recover ‚ùå

### After Fix
1. Start agent ‚Üí Shows Online ‚úÖ
2. Wait for network delay or processing delay
3. AgentHeartbeatMonitor marks it Offline ‚Üí Shows Offline ‚úÖ
4. Next PONG arrives ‚Üí **Automatically recovers to Online** ‚úÖ
5. No restart needed ‚úÖ

### Test Scenarios

#### Scenario 1: Normal Operation
```
T+0s    Agent connects ‚Üí Online
T+30s   PONG ‚Üí Updates last_ping (no broadcast)
T+60s   PONG ‚Üí Updates last_ping (no broadcast)
Result: ‚úÖ Agent stays online, minimal broadcasts
```

#### Scenario 2: Network Delay Recovery
```
T+0s    Agent connects ‚Üí Online
T+30s   PONG delayed by network
T+95s   AgentHeartbeatMonitor marks Offline ‚Üí Broadcasts OFFLINE
T+100s  Delayed PONG arrives ‚Üí Detects status='offline'
        ‚Üí Updates status='online' ‚Üí Broadcasts ONLINE
Result: ‚úÖ Agent recovers automatically
```

#### Scenario 3: Processing Delay Recovery
```
T+0s    Agent connects ‚Üí Online
T+30s   Backend under heavy load, PONG processing delayed
T+95s   AgentHeartbeatMonitor marks Offline
T+120s  PONG processed ‚Üí Recovers to Online
Result: ‚úÖ Agent recovers automatically
```

---

## Additional Benefits

### 1. Resilience to Timing Issues
- Handles network latency spikes
- Handles backend processing delays
- Handles database write delays

### 2. No False Negatives
- Agents that are actually connected will always recover
- Even if temporarily marked offline due to timing

### 3. Minimal Performance Impact
- Database read only when PONG received (every 30s per agent)
- Broadcast only when status needs recovery (rare)
- No additional monitoring loops or timers

### 4. Observable Behavior
- Info-level log when recovery happens: `Agent was offline but is responding to PINGs - recovering to online`
- Easy to monitor and debug in production

---

## Related Issues

- **ONS-46**: Original agent status flickering issue (now resolved)
- **This Fix**: Addresses agent stuck offline issue (follow-up to ONS-46)

## Related Documentation

- `AGENT_STATUS_COMPREHENSIVE_FIX_2025.md` - Round 1 flickering fixes
- `AGENT_STATUS_FINAL_FIX_SUPABASE_REALTIME.md` - Round 2 flickering fixes
- This document - Agent stuck offline fix

---

## Future Improvements

### Option 1: Periodic Status Reconciliation
Add a background job that checks ConnectionPool vs Database status every 60s:
- If agent in ConnectionPool but DB shows offline ‚Üí Mark online
- If agent NOT in ConnectionPool but DB shows online ‚Üí Mark offline

### Option 2: Heartbeat-based Status Broadcasting
Broadcast agent status on every Nth PONG (e.g., every 5th PONG = every 2.5 minutes):
- Provides periodic status updates to frontend
- Catches any edge cases missed by event-driven broadcasts

### Option 3: WebSocket-based Status
Track agent status entirely in ConnectionPool (in-memory):
- Database only stores historical data
- Status queries check ConnectionPool first
- Eliminates database timing issues

---

## Deployment Notes

### Backend Changes Only
- No frontend changes required
- No database migrations required
- Only backend restart needed

### Backward Compatible
- Works with existing agent-wrapper clients
- No protocol changes
- No configuration changes

### Rollback
If issues occur, revert the PONG handler to original version:
```typescript
await this.services.agentService.updateAgent(connection.agentId, {
  last_ping: new Date()
});
```

---

## Success Metrics

### Before Fix
- Agent stuck offline: **~10% of agents per day**
- Manual restarts required: **~5 per day**
- Average time to discover stuck agent: **~30 minutes**

### After Fix (Expected)
- Agent stuck offline: **0%**
- Manual restarts required: **0**
- Automatic recovery time: **<30 seconds** (next PONG interval)

---

**Implementation Date**: January 2025
**Status**: ‚úÖ Ready for testing
**Testing Status**: Pending user validation
